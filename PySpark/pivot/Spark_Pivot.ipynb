{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e5f0f394",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "findspark.init()\n",
    "spark = SparkSession.builder.master(\"local[3]\").appName(\"spark_pivot\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6fec886e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+-----------+\n",
      "|Company|Price|    Country|\n",
      "+-------+-----+-----------+\n",
      "| Toyota|15000|      India|\n",
      "|    Kia|18000|South Korea|\n",
      "|   Ford|14000|      India|\n",
      "|Renault|12000|     France|\n",
      "|Renault|10000|      India|\n",
      "| Toyota|12000|      Japan|\n",
      "|    Kia|16000|South Korea|\n",
      "|   Ford|13000|        USA|\n",
      "|Renault|12000|South Korea|\n",
      "| Toyota|15000|      Japan|\n",
      "|    Kia|13000|South Korea|\n",
      "|   Ford|10000|      India|\n",
      "+-------+-----+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [(\"Toyota\",15000,\"India\"), (\"Kia\",18000,\"South Korea\"), (\"Ford\",14000,\"India\"),\n",
    "      (\"Renault\",12000,\"France\"),(\"Renault\",10000,\"India\"),(\"Toyota\",12000,\"Japan\"),\n",
    "      (\"Kia\",16000,\"South Korea\"),(\"Ford\",13000,\"USA\"),(\"Renault\",12000,\"South Korea\"),\n",
    "      (\"Toyota\",15000,\"Japan\"),(\"Kia\",13000,\"South Korea\"),(\"Ford\",10000,\"India\")]\n",
    "\n",
    "\n",
    "df = spark.createDataFrame(data,[\"Company\",\"Price\",\"Country\"])\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e616bc",
   "metadata": {},
   "source": [
    "## To Pivot or transporse columns , think about three things\n",
    "+ The columnname that you are going to groupby (Equivalent to <b>ROWS</b> in an excel pivot)\n",
    "+ The columnname that you are going to pass to pivot  (Equivalent to <b>COLUMNS</b> in an excel pivot)\n",
    "+ The columnname that you are going to apply a aggrgate functon (equivalent to <b>VALUES</b> in an excel pivot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6301358f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+-----+-----+-----------+----+\n",
      "|Company|France|India|Japan|South Korea| USA|\n",
      "+-------+------+-----+-----+-----------+----+\n",
      "|    Kia|  null| null| null|          3|null|\n",
      "|Renault|     1|    1| null|          1|null|\n",
      "| Toyota|  null|    1|    2|       null|null|\n",
      "|   Ford|  null|    2| null|       null|   1|\n",
      "+-------+------+-----+-----+-----------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"Company\").pivot(\"Country\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d297f5a9",
   "metadata": {},
   "source": [
    "### Shape of the output\n",
    "+ Number of rows in the output depends on the unique values of the groupBy operation. 4 in this example\n",
    "+ Number of columns in the output depends on the unique values passed to pivot (5) + number of columns passed to groupBy (1)\n",
    "   + For eg, 5+1=6 in this example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f45143f",
   "metadata": {},
   "source": [
    "### Applying different aggregate functions\n",
    "+ count aggregate doesn't require a column name\n",
    "+ Except count all the other aggregate functions require an integer column to be passed. \n",
    "    + For ex: sum('salary') and not sum('product') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cace6793",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivotDF = df.groupBy(\"Company\").pivot(\"Country\").sum('Price')\n",
    "pivotDF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1213aed",
   "metadata": {},
   "source": [
    "## Two step Process to improve pivot performance\n",
    "##### Spark > 2.1 internally uses this process "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c01493",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupBy(\"Company\",\"Country\").sum('Price').\\\n",
    "    groupBy('Company').pivot(\"Country\").\\\n",
    "    sum('sum(Price)').show() # the column used is sum(Amount) ,not 'Amount'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381bc612",
   "metadata": {},
   "source": [
    "### Notes about Pivot\n",
    "+ pivot is applied on grouped data, not on top of a dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d502cc",
   "metadata": {},
   "source": [
    "## Pivot_Table\n",
    "+ Apply spreadsheet like Pivot \n",
    "  + Index (What are the output rows?) \n",
    "  + Columns (pivot column) - What are the output columns?\n",
    "  + aggfunc is to pass the aggregate function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b900b665",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pandas = df.toPandas()\n",
    "df_pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5327c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = df_pandas.pivot_table(values='Price', index='Company',\n",
    "                       columns='Country', aggfunc='sum')\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b38209",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use fill_value to fill na\n",
    "table = df_pandas.pivot_table(values='Price', index='Company',\n",
    "                       columns='Country', aggfunc='sum',fill_value=0)\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aaea6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column specific aggregation . Pass column to be aggregated as dictionary to aggfunc\n",
    "table = df_pandas.pivot_table(values='Price', index='Company',\n",
    "                       columns='Country', aggfunc={'Price':'sum'},fill_value=0)\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf4b60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply aggregates on multiple tables\n",
    "# Lets add one more column\n",
    "df_pandas['Commission']=df_pandas['Price']*.07\n",
    "df_pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe34c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column specific aggregation \n",
    "table = df_pandas.pivot_table(values=['Price','Commission'], index='Company',\n",
    "                       columns='Country', aggfunc={'Price':'sum','Commission':'mean'},fill_value=0)\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b163ea",
   "metadata": {},
   "source": [
    "## Unpivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65362d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivotDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba28dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import expr\n",
    "\n",
    "unPivotDF = pivotDF.select(\"Company\",\n",
    "expr(\"stack(5, 'France', France, 'India', India, 'Japan', Japan,'South Korea',`South Korea`,'USA',USA) as (Country,Total)\")).\\\n",
    "where(\"Total is not null\")\n",
    "\n",
    "unPivotDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cad293",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
